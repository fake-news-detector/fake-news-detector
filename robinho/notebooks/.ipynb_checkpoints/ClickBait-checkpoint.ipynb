{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0           0  20 imagens que, por incr√≠vel que pare√ßa, n√£o s...   \n",
      "1           1  24 filmes da Disney explicados por homens que ...   \n",
      "2           2  Todo mundo √© uma princesa da Disney OU um her√≥...   \n",
      "3           3  Quais s√£o as tr√™s comidas que combinam com a s...   \n",
      "4           4  Este teste sobre comida vai dizer de uma vez p...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.buzzfeed.com/daves4/animais-penis-...  \n",
      "1  https://www.buzzfeed.com/keelyflaherty/filmes-...  \n",
      "2  https://www.buzzfeed.com/perpetua/teste-prince...  \n",
      "3  https://www.buzzfeed.com/joannaborns/teste-tre...  \n",
      "4  https://www.buzzfeed.com/joannaborns/teste-com...  \n",
      "   Unnamed: 0                                              title  \\\n",
      "0           0  Nem todos que assinam manifesto pr√≥-Boulos dec...   \n",
      "1           1  Centenas de professores universit√°rios n√£o est...   \n",
      "2           2  Janaina Paschoal diz que ser vice de Bolsonaro...   \n",
      "3           3  Russomanno vira s√≥cio de startup financeira qu...   \n",
      "4           4  Governo errou na pol√≠tica para combust√≠veis, d...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.buzzfeed.com/tatianafarah/frei-bet...  \n",
      "1  https://www.buzzfeed.com/felitti/centenas-de-p...  \n",
      "2  https://www.buzzfeed.com/tatianafarah/janaina-...  \n",
      "3  https://www.buzzfeed.com/alexandrearagao/russo...  \n",
      "4  https://www.buzzfeed.com/severinomotta/governo...  \n",
      "                                                   0\n",
      "0                                 Should I Get Bings\n",
      "1      Which TV Female Friend Group Do You Belong In\n",
      "2  The New \"Star Wars: The Force Awakens\" Trailer...\n",
      "3  This Vine Of New York On \"Celebrity Big Brothe...\n",
      "4  A Couple Did A Stunning Photo Shoot With Their...\n",
      "                                                   0\n",
      "0  Bill Changing Credit Card Rules Is Sent to Oba...\n",
      "1  In Hollywood, the Easy-Money Generation Toughe...\n",
      "2  1700 runners still unaccounted for in UK's Lak...\n",
      "3  Yankees Pitchers Trade Fielding Drills for Put...\n",
      "4  Large earthquake rattles Indonesia; Seventh in...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category_id</th>\n",
       "      <th>clickbait_title</th>\n",
       "      <th>content</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>verified_category_id</th>\n",
       "      <th>verified_clickbait_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tweet\\n\\nThe Environmental Protection Agency (...</td>\n",
       "      <td>1</td>\n",
       "      <td>2078</td>\n",
       "      <td>Wolf in Sheep‚Äôs Clothing (or a Scientist‚Äôs Lab...</td>\n",
       "      <td>http://www.pogo.org/blog/2018/05/wolf_in_sheep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Reveja todos os finais de 'O Outro Lado'\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>2077</td>\n",
       "      <td>globo.com - Absolutamente tudo sobre not√≠cias,...</td>\n",
       "      <td>https://www.globo.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A black Yale student was taking a nap in a com...</td>\n",
       "      <td>1</td>\n",
       "      <td>2076</td>\n",
       "      <td>White people keep calling the cops on black pe...</td>\n",
       "      <td>https://www.vox.com/identities/2018/5/11/17340...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday afternoon, the Justice Department relea...</td>\n",
       "      <td>1</td>\n",
       "      <td>2075</td>\n",
       "      <td>Donald Trump, Bernie Sanders, and Jill Stein a...</td>\n",
       "      <td>https://www.vox.com/policy-and-politics/2018/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I regularly attend an annual security conferen...</td>\n",
       "      <td>1</td>\n",
       "      <td>2074</td>\n",
       "      <td>John McCain: ‚ÄòVladimir Putin Is an Evil Man‚Äô</td>\n",
       "      <td>https://www.wsj.com/articles/john-mccain-vladi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  category_id  clickbait_title  \\\n",
       "0           0            1              0.0   \n",
       "1           1            1              0.0   \n",
       "2           2            1              NaN   \n",
       "3           3            1              NaN   \n",
       "4           4            1              0.0   \n",
       "\n",
       "                                             content  count    id  \\\n",
       "0  Tweet\\n\\nThe Environmental Protection Agency (...      1  2078   \n",
       "1         Reveja todos os finais de 'O Outro Lado'\\n      1  2077   \n",
       "2  A black Yale student was taking a nap in a com...      1  2076   \n",
       "3  Friday afternoon, the Justice Department relea...      1  2075   \n",
       "4  I regularly attend an annual security conferen...      1  2074   \n",
       "\n",
       "                                               title  \\\n",
       "0  Wolf in Sheep‚Äôs Clothing (or a Scientist‚Äôs Lab...   \n",
       "1  globo.com - Absolutamente tudo sobre not√≠cias,...   \n",
       "2  White people keep calling the cops on black pe...   \n",
       "3  Donald Trump, Bernie Sanders, and Jill Stein a...   \n",
       "4       John McCain: ‚ÄòVladimir Putin Is an Evil Man‚Äô   \n",
       "\n",
       "                                                 url  verified_category_id  \\\n",
       "0  http://www.pogo.org/blog/2018/05/wolf_in_sheep...                   NaN   \n",
       "1                             https://www.globo.com/                   NaN   \n",
       "2  https://www.vox.com/identities/2018/5/11/17340...                   NaN   \n",
       "3  https://www.vox.com/policy-and-politics/2018/2...                   NaN   \n",
       "4  https://www.wsj.com/articles/john-mccain-vladi...                   NaN   \n",
       "\n",
       "   verified_clickbait_title  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "buzzfeedbr_clickbait_titles = pd.read_csv(\"../train_data/buzzfeedbr/clickbait_titles.csv\")\n",
    "print(buzzfeedbr_clickbait_titles[0:5])\n",
    "\n",
    "buzzfeedbr_non_clickbait_titles = pd.read_csv(\"../train_data/buzzfeedbr/non_clickbait_titles.csv\")\n",
    "print(buzzfeedbr_non_clickbait_titles[0:5])\n",
    "\n",
    "clickbait_titles = pd.read_csv(\"../train_data/bhargaviparanjape/clickbait_data.csv\", sep=\"\\n\", header=None)\n",
    "print(clickbait_titles[0:5])\n",
    "\n",
    "non_clickbait_titles = pd.read_csv(\"../train_data/bhargaviparanjape/non_clickbait_data.csv\", sep=\"\\n\", header=None)\n",
    "print(non_clickbait_titles[0:5])\n",
    "\n",
    "all_links = pd.read_csv(\"../train_data/links.csv\")\n",
    "all_links[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of click bait samples 164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pay Little Wanderers NYC using PayPal.Me</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evangelical Christian Radio Host Says Nothing ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did Armed Trump Supporters Ask a Navajo Legisl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'SPYGATE': Trump ramps up attacks on FBI, Russ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top intel official says Chinese ZTE cellphones...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lesley Stahl: Trump admitted mission to \"discr...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tomi Lahren Gets Owned By Genealogist After He...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMH: Tomi Lahren Gets A Drink Thrown At Her At...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trump's norm-breaking is leading to a constitu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Richard Painter says there is more evidence ag...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Theory: Playboy Model Had Affair With Trump, N...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jared Kushner‚Äôs startup is seeking $100 millio...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Judge‚Äôs contempt finding on Kobach still stand...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Is this Playboy model keeping the biggest secr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A Venezuela √© palco de uma batalha global deci...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Conhe√ßa a mulher por tr√°s da s√©rie Cosmos</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lazzo Matumbi fala sobre 'Atr√°s do Por do Sol'...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MBL - Movimento Brasil Livre - P√°gina inicial</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Top 10 Mysterious Things Found Frozen In Ice A...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>O mito do uso de 10% do c√©rebro</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Neil deGrasse Tyson diz que seu novo v√≠deo tal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I am excited to start the European part of my ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Congratulations, Kyle Kashuv! No. 1 in his cla...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Donna abruzzese lascia 3 milioni di euro a Sil...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Crowd Cheers As 93-Year-Old Fuckup Finally Gra...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Joe Rogan - Adolf Hitler Escaped To South Amer...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Georgia 2018: Hillary Clinton endorses Abrams ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Teste feito por equipe da Unicamp revelou falh...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RNC paid nearly half a million dollars to law ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Trump to Demand Investigation Into Whether FBI...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>8 truques que os pintores de paredes n√£o conta...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>O atentado de Jana√∫ba que dilacerou a vida de ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>A trajet√≥ria das tarifas de energia nos √∫ltimo...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>Google Pixel 2 ter√° atualiza√ß√µes do Android e ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>Tyrese Congratulates The Rock For Ruining The ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>Em feira de Luisa Mell, pessoas v√£o embora ao ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>O apocalipse foi apenas adiado no novo trailer...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Woman Gives Birth In Japan, Shows What Food Sh...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Comer de Gra√ßa no Zaffari, Beringela Baby e Xi...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>Como a queda da Selic vai afetar a poupan√ßa</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>Firefox faz mudan√ßa no logo para marcar uso do...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>Como cientistas criaram um algoritmo que ‚Äòprod...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>TIM aumenta internet no p√≥s-pago com b√¥nus de ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>Acusado de matar travesti √© absolvido em 1¬∞ j√∫...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>Em 10 anos, aprender a usar emojis ser√° mais i...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>Receber mais curtidas na sua foto crian√ßa no F...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>Celulares come√ßam a ser vendidos com outro apa...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Ap√≥s artigo de general defendendo golpe, Estad...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Grupo sequestra Obama e s√≥ o libera se ele se ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Estado Isl√¢mico assume pl√°stica de Ivana Trump</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>Ap√≥s temporada na Coreia, censura far√° turn√™ n...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>Facebook retira coment√°rios e deixa apenas bot...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>Mudan√ßa na Rouanet pro√≠be a B√≠blia, que est√° c...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>Kesha falou sobre que tipo de amiga a Taylor S...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>Em sil√™ncio, reforma eleitoral criou censura n...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>Mulher acusa laborat√≥rio Fleury de racismo por...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>A hashtag #posteseuviralata est√° enchendo o Tw...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>Site Lan√ßa Card√°pio Fit (low-carb) e √© Nova Se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>15 destinos para conhecer de trem</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>STF decide hoje se v√≠deo de A√©cio explicando m...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  is_clickbait\n",
       "0              Pay Little Wanderers NYC using PayPal.Me           0.5\n",
       "1     Evangelical Christian Radio Host Says Nothing ...           0.0\n",
       "2     Did Armed Trump Supporters Ask a Navajo Legisl...           0.0\n",
       "3     'SPYGATE': Trump ramps up attacks on FBI, Russ...           0.5\n",
       "4     Top intel official says Chinese ZTE cellphones...           0.5\n",
       "5     Lesley Stahl: Trump admitted mission to \"discr...           0.5\n",
       "6     Tomi Lahren Gets Owned By Genealogist After He...           1.0\n",
       "7     SMH: Tomi Lahren Gets A Drink Thrown At Her At...           0.5\n",
       "9     Trump's norm-breaking is leading to a constitu...           0.0\n",
       "10    Richard Painter says there is more evidence ag...           0.5\n",
       "11    Theory: Playboy Model Had Affair With Trump, N...           0.5\n",
       "12    Jared Kushner‚Äôs startup is seeking $100 millio...           0.5\n",
       "13    Judge‚Äôs contempt finding on Kobach still stand...           0.5\n",
       "14    Is this Playboy model keeping the biggest secr...           0.0\n",
       "15    A Venezuela √© palco de uma batalha global deci...           1.0\n",
       "16            Conhe√ßa a mulher por tr√°s da s√©rie Cosmos           0.0\n",
       "17    Lazzo Matumbi fala sobre 'Atr√°s do Por do Sol'...           0.0\n",
       "18        MBL - Movimento Brasil Livre - P√°gina inicial           1.0\n",
       "19    Top 10 Mysterious Things Found Frozen In Ice A...           1.0\n",
       "20                      O mito do uso de 10% do c√©rebro           0.0\n",
       "21    Neil deGrasse Tyson diz que seu novo v√≠deo tal...           0.0\n",
       "22    I am excited to start the European part of my ...           0.0\n",
       "23    Congratulations, Kyle Kashuv! No. 1 in his cla...           0.5\n",
       "24    Donna abruzzese lascia 3 milioni di euro a Sil...           1.0\n",
       "25    Crowd Cheers As 93-Year-Old Fuckup Finally Gra...           1.0\n",
       "26    Joe Rogan - Adolf Hitler Escaped To South Amer...           1.0\n",
       "27    Georgia 2018: Hillary Clinton endorses Abrams ...           0.5\n",
       "28    Teste feito por equipe da Unicamp revelou falh...           0.0\n",
       "29    RNC paid nearly half a million dollars to law ...           0.0\n",
       "30    Trump to Demand Investigation Into Whether FBI...           0.5\n",
       "...                                                 ...           ...\n",
       "2089  8 truques que os pintores de paredes n√£o conta...           1.0\n",
       "2090  O atentado de Jana√∫ba que dilacerou a vida de ...           0.5\n",
       "2091  A trajet√≥ria das tarifas de energia nos √∫ltimo...           0.5\n",
       "2092  Google Pixel 2 ter√° atualiza√ß√µes do Android e ...           0.5\n",
       "2093  Tyrese Congratulates The Rock For Ruining The ...           0.5\n",
       "2094  Em feira de Luisa Mell, pessoas v√£o embora ao ...           0.5\n",
       "2095  O apocalipse foi apenas adiado no novo trailer...           0.5\n",
       "2096  Woman Gives Birth In Japan, Shows What Food Sh...           1.0\n",
       "2097  Comer de Gra√ßa no Zaffari, Beringela Baby e Xi...           0.5\n",
       "2098        Como a queda da Selic vai afetar a poupan√ßa           0.5\n",
       "2099  Firefox faz mudan√ßa no logo para marcar uso do...           0.5\n",
       "2100  Como cientistas criaram um algoritmo que ‚Äòprod...           0.5\n",
       "2101  TIM aumenta internet no p√≥s-pago com b√¥nus de ...           0.5\n",
       "2102  Acusado de matar travesti √© absolvido em 1¬∞ j√∫...           0.5\n",
       "2103  Em 10 anos, aprender a usar emojis ser√° mais i...           0.5\n",
       "2104  Receber mais curtidas na sua foto crian√ßa no F...           0.5\n",
       "2105  Celulares come√ßam a ser vendidos com outro apa...           0.5\n",
       "2106  Ap√≥s artigo de general defendendo golpe, Estad...           0.5\n",
       "2107  Grupo sequestra Obama e s√≥ o libera se ele se ...           0.5\n",
       "2108     Estado Isl√¢mico assume pl√°stica de Ivana Trump           0.5\n",
       "2109  Ap√≥s temporada na Coreia, censura far√° turn√™ n...           0.5\n",
       "2110  Facebook retira coment√°rios e deixa apenas bot...           0.5\n",
       "2111  Mudan√ßa na Rouanet pro√≠be a B√≠blia, que est√° c...           0.5\n",
       "2112  Kesha falou sobre que tipo de amiga a Taylor S...           1.0\n",
       "2113  Em sil√™ncio, reforma eleitoral criou censura n...           0.5\n",
       "2115  Mulher acusa laborat√≥rio Fleury de racismo por...           0.5\n",
       "2116  A hashtag #posteseuviralata est√° enchendo o Tw...           0.5\n",
       "2117  Site Lan√ßa Card√°pio Fit (low-carb) e √© Nova Se...           1.0\n",
       "2118                  15 destinos para conhecer de trem           0.5\n",
       "2119  STF decide hoje se v√≠deo de A√©cio explicando m...           0.5\n",
       "\n",
       "[1314 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = all_links.copy()\n",
    "\n",
    "df['title'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=[\"title\"], inplace=True)\n",
    "df = df.loc[df['title'].str.len() > 30]\n",
    "\n",
    "df[\"clickbait_title\"] = df['verified_clickbait_title'].fillna(df['clickbait_title'])\n",
    "\n",
    "df[\"is_clickbait\"] = [ 0 if c == 0 else 1 if c == 1 else 0.5 for c in df['clickbait_title'] ]\n",
    "\n",
    "df = df[[\"title\", \"is_clickbait\"]]\n",
    "\n",
    "print(\"Number of click bait samples\", len(df[df[\"is_clickbait\"] == 1]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default classification approach, ignoring \"I don't know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    7.1s finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>tfidf__max_df</th>\n",
       "      <th>tfidf__min_df</th>\n",
       "      <th>tfidf__token_pattern</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.620094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.624098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.630742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.624223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.623281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.614153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.621734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.606199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.347618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.340246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.554712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.522511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.402266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.197693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.516835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.545901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>[A-Za-z0-9]+</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  clf  tfidf__max_df  \\\n",
       "0   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "1   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "2   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "3   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.5   \n",
       "4   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "5   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "6   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "7   MultinomialNB(alpha=1.0, class_prior=None, fit...            0.1   \n",
       "8   (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "9   (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "10  (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "11  (DecisionTreeClassifier(class_weight=None, cri...            0.5   \n",
       "12  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "13  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "14  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "15  (DecisionTreeClassifier(class_weight=None, cri...            0.1   \n",
       "16  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "17  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "18  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "19  DummyClassifier(constant=1.0, random_state=Non...            0.5   \n",
       "20  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "21  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "22  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "23  DummyClassifier(constant=1.0, random_state=Non...            0.1   \n",
       "\n",
       "    tfidf__min_df tfidf__token_pattern  mean_test_score  \n",
       "0               1         [A-Za-z0-9]+         0.620094  \n",
       "1               1        (?u)\\b\\w\\w+\\b         0.624098  \n",
       "2               2         [A-Za-z0-9]+         0.630742  \n",
       "3               2        (?u)\\b\\w\\w+\\b         0.624223  \n",
       "4               1         [A-Za-z0-9]+         0.623281  \n",
       "5               1        (?u)\\b\\w\\w+\\b         0.614153  \n",
       "6               2         [A-Za-z0-9]+         0.621734  \n",
       "7               2        (?u)\\b\\w\\w+\\b         0.606199  \n",
       "8               1         [A-Za-z0-9]+         0.347618  \n",
       "9               1        (?u)\\b\\w\\w+\\b         0.340246  \n",
       "10              2         [A-Za-z0-9]+         0.554712  \n",
       "11              2        (?u)\\b\\w\\w+\\b         0.522511  \n",
       "12              1         [A-Za-z0-9]+         0.402266  \n",
       "13              1        (?u)\\b\\w\\w+\\b         0.197693  \n",
       "14              2         [A-Za-z0-9]+         0.516835  \n",
       "15              2        (?u)\\b\\w\\w+\\b         0.545901  \n",
       "16              1         [A-Za-z0-9]+         0.666667  \n",
       "17              1        (?u)\\b\\w\\w+\\b         0.666667  \n",
       "18              2         [A-Za-z0-9]+         0.666667  \n",
       "19              2        (?u)\\b\\w\\w+\\b         0.666667  \n",
       "20              1         [A-Za-z0-9]+         0.666667  \n",
       "21              1        (?u)\\b\\w\\w+\\b         0.666667  \n",
       "22              2         [A-Za-z0-9]+         0.666667  \n",
       "23              2        (?u)\\b\\w\\w+\\b         0.666667  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "positive_df = df[df[\"is_clickbait\"] == 1]\n",
    "negative_df = df[df[\"is_clickbait\"] == 0].apply(np.random.permutation)[0:len(positive_df)]\n",
    "balanced_df = positive_df.append(negative_df)\n",
    "balanced_df = balanced_df.reindex(np.random.permutation(balanced_df.index))\n",
    "\n",
    "X = balanced_df\n",
    "y = balanced_df[\"is_clickbait\"]\n",
    "y = [ False if yi == 0 else True for yi in y ]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=2, token_pattern='[A-Za-z0-9]+')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipeline, verbose=1, scoring='f1', param_grid={\n",
    "    'clf': [\n",
    "        MultinomialNB(),\n",
    "        RandomForestClassifier(),\n",
    "        DummyClassifier(\"constant\", constant=1.0)\n",
    "    ],\n",
    "    'tfidf__max_df': [0.5, 0.1],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'tfidf__token_pattern': ['[A-Za-z0-9]+', r\"(?u)\\b\\w\\w+\\b\"]\n",
    "})\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "results['clf'] = [ p['clf'] for p in results['params'] ]\n",
    "results['tfidf__max_df'] = [ p['tfidf__max_df'] for p in results['params'] ]\n",
    "results['tfidf__min_df'] = [ p['tfidf__min_df'] for p in results['params'] ]\n",
    "results['tfidf__token_pattern'] = [ p['tfidf__token_pattern'] for p in results['params'] ]\n",
    "results[['clf', 'tfidf__max_df', 'tfidf__min_df', 'tfidf__token_pattern', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor Appoach, taking \"I don't know\" into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>facts about the iss - Google Search</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>O que espanta no caso de Marcelo Sereno - O An...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Tout ce qu'il faut savoir pour prendre soin d'...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Pyongyang ne renoncera jamais enti√®rement √† se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Fato in√©dito na hist√≥ria do Bar√ßa!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Lula joga a toalha - O Antagonista</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Hillary Clinton: Destroy Syria for Israel: ¬´¬†T...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>SATURDAY OF LAZARUS by Archpriest Timothy Crem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Edit: FOI AGREDIDO, N√ÉO! AGREDIU VERBALMENTE P...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Artistas da lacra√ß√£o socialista: Pabllo Vittar...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>üö®üö® No Consuman Estos Productos Gracias .üö®üö® COM...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>#FOR√áALULA ‚ô• Curta Gera√ß√£o Coca-Cola</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Brad Marchand r√©plique au Canadien sur Twitter...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Effects of Climate Change ‚ÄòIrreversible,‚Äô U.N....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Gleisi Hoffmann d√° o recado: Lula √© o nosso ca...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Billionaires made enough money in 2017 to end ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Comer de Gra√ßa no Zaffari, Beringela Baby e Xi...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Fake News Detector - Chrome Web Store</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Sal do himalaia faz mal? Descubra agora | Corp...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Quick-thinking Mom Saves Family‚Äôs Life By Givi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Alice Paquet r√©agit aux r√©v√©lations de la nouv...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Vazou √°udio no whatsapp contra o Galo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Mozilla Joins George Soros's Efforts In Launch...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Har du Rh-negativt blod? Du kan vara en utomjo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Receber mais curtidas na sua foto crian√ßa no F...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Candidatos ter√£o ‚Äòtr√©gua‚Äô da Lava Jato at√© fim...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>Will You Be Happy Or Unhappy In 2018?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>O Estado n√£o gosta de concorr√™ncia ;)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>The New Doctor Who: 8 Things We Know (And 7 Cr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Alek Minassian: 5 Fast Facts You Need to Know ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Heat on Stormy Daniels' lawyer over past busin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Il faut redonner √† la vie politique ses lettre...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Eliane Cantanh√™de diz que cubanos est√£o chegan...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>The Bible Says The World Is Going To End On Ju...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Telegram agora permite compartilhar sua locali...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>This Man Has Kept an Unopened Christmas Presen...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Avi√£o joga veneno sobre fam√≠lias de sem terra ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>Por que Dona Regina esmagou esquerdistas apena...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Entrevista com Selton Mello | The Noite (21/03...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Uma tasca aut√™ntica, com direito √† mesa na cal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>Amazon Go: Retail Store of the Future</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>Procuradoria espanhola solicita cadeia para jo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Rajoy confunde al primer ministro dan√©s con el...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>S√≥ pessoas com olhos de √°guia conseguir√£o enco...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Facebook stops putting \"Disputed Flags\" on fak...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Sheriff: Secret Service investigating vandalis...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Warcraft Logs - Combat Analysis for Warcraft</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>‚ÄòHurting us more than he knows‚Äô: The steelwork...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Robert Mueller is on @TIME's list of the world...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Leil√£o novos e usados: Santorini+Exp, Lost Leg...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>I'm sorry I had to cancel the first 5 recitals...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Catalunya se llena de adoquines en memoria de ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>√â isto o que os seus olhos revelam sobre sua a...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>TOP 10 animais BIZARROS que de fato existem ou...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Jim Carrey Slammed By Fox News For 'Disgracefu...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Have scientists really admitted climate change...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>The recent mobilizations in the city of Jerada...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Tina Fey defends Michelle Wolf and has a sugge...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Caso Lula: Jurista diz que pris√£o ap√≥s segunda...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>EXCLUSIVE: Robert Mercer backed a secretive gr...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  is_clickbait\n",
       "1552                facts about the iss - Google Search           1.0\n",
       "185   O que espanta no caso de Marcelo Sereno - O An...           0.0\n",
       "144   Tout ce qu'il faut savoir pour prendre soin d'...           0.0\n",
       "89    Pyongyang ne renoncera jamais enti√®rement √† se...           1.0\n",
       "2046                 Fato in√©dito na hist√≥ria do Bar√ßa!           1.0\n",
       "290                  Lula joga a toalha - O Antagonista           0.0\n",
       "32    Hillary Clinton: Destroy Syria for Israel: ¬´¬†T...           1.0\n",
       "221   SATURDAY OF LAZARUS by Archpriest Timothy Crem...           0.0\n",
       "180   Edit: FOI AGREDIDO, N√ÉO! AGREDIU VERBALMENTE P...           0.0\n",
       "431   Artistas da lacra√ß√£o socialista: Pabllo Vittar...           0.5\n",
       "146   üö®üö® No Consuman Estos Productos Gracias .üö®üö® COM...           1.0\n",
       "317                #FOR√áALULA ‚ô• Curta Gera√ß√£o Coca-Cola           0.5\n",
       "142   Brad Marchand r√©plique au Canadien sur Twitter...           1.0\n",
       "331   Effects of Climate Change ‚ÄòIrreversible,‚Äô U.N....           0.0\n",
       "167   Gleisi Hoffmann d√° o recado: Lula √© o nosso ca...           0.0\n",
       "427   Billionaires made enough money in 2017 to end ...           0.5\n",
       "479   Comer de Gra√ßa no Zaffari, Beringela Baby e Xi...           0.5\n",
       "1755              Fake News Detector - Chrome Web Store           1.0\n",
       "456   Sal do himalaia faz mal? Descubra agora | Corp...           0.5\n",
       "79    Quick-thinking Mom Saves Family‚Äôs Life By Givi...           1.0\n",
       "170   Alice Paquet r√©agit aux r√©v√©lations de la nouv...           0.0\n",
       "1807              Vazou √°udio no whatsapp contra o Galo           1.0\n",
       "1603  Mozilla Joins George Soros's Efforts In Launch...           1.0\n",
       "171   Har du Rh-negativt blod? Du kan vara en utomjo...           1.0\n",
       "81    Receber mais curtidas na sua foto crian√ßa no F...           0.5\n",
       "241   Candidatos ter√£o ‚Äòtr√©gua‚Äô da Lava Jato at√© fim...           1.0\n",
       "1660              Will You Be Happy Or Unhappy In 2018?           1.0\n",
       "58                O Estado n√£o gosta de concorr√™ncia ;)           0.5\n",
       "1862  The New Doctor Who: 8 Things We Know (And 7 Cr...           1.0\n",
       "373   Alek Minassian: 5 Fast Facts You Need to Know ...           0.0\n",
       "...                                                 ...           ...\n",
       "36    Heat on Stormy Daniels' lawyer over past busin...           0.0\n",
       "28    Il faut redonner √† la vie politique ses lettre...           0.0\n",
       "470   Eliane Cantanh√™de diz que cubanos est√£o chegan...           1.0\n",
       "282   The Bible Says The World Is Going To End On Ju...           0.5\n",
       "106   Telegram agora permite compartilhar sua locali...           0.5\n",
       "1654  This Man Has Kept an Unopened Christmas Presen...           1.0\n",
       "38    Avi√£o joga veneno sobre fam√≠lias de sem terra ...           0.5\n",
       "2059  Por que Dona Regina esmagou esquerdistas apena...           1.0\n",
       "333   Entrevista com Selton Mello | The Noite (21/03...           0.0\n",
       "372   Uma tasca aut√™ntica, com direito √† mesa na cal...           0.0\n",
       "1518              Amazon Go: Retail Store of the Future           1.0\n",
       "771   Procuradoria espanhola solicita cadeia para jo...           1.0\n",
       "184   Rajoy confunde al primer ministro dan√©s con el...           0.0\n",
       "1972  S√≥ pessoas com olhos de √°guia conseguir√£o enco...           1.0\n",
       "271   Facebook stops putting \"Disputed Flags\" on fak...           0.5\n",
       "152   Sheriff: Secret Service investigating vandalis...           0.0\n",
       "107        Warcraft Logs - Combat Analysis for Warcraft           0.0\n",
       "411   ‚ÄòHurting us more than he knows‚Äô: The steelwork...           0.5\n",
       "260   Robert Mueller is on @TIME's list of the world...           0.0\n",
       "76    Leil√£o novos e usados: Santorini+Exp, Lost Leg...           0.5\n",
       "101   I'm sorry I had to cancel the first 5 recitals...           0.0\n",
       "252   Catalunya se llena de adoquines en memoria de ...           0.5\n",
       "110   √â isto o que os seus olhos revelam sobre sua a...           0.5\n",
       "632   TOP 10 animais BIZARROS que de fato existem ou...           1.0\n",
       "268   Jim Carrey Slammed By Fox News For 'Disgracefu...           0.5\n",
       "351   Have scientists really admitted climate change...           0.0\n",
       "359   The recent mobilizations in the city of Jerada...           0.0\n",
       "263   Tina Fey defends Michelle Wolf and has a sugge...           0.0\n",
       "300   Caso Lula: Jurista diz que pris√£o ap√≥s segunda...           0.5\n",
       "461   EXCLUSIVE: Robert Mercer backed a secretive gr...           0.5\n",
       "\n",
       "[492 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = df[df[\"is_clickbait\"] == 1]\n",
    "negative_df = df[df[\"is_clickbait\"] == 0].apply(np.random.permutation)[0:len(positive_df)]\n",
    "idk_df = df[(df[\"is_clickbait\"] != 0) & (df[\"is_clickbait\"] != 1)].apply(np.random.permutation)[0:len(positive_df)]\n",
    "balanced_df = positive_df.append(negative_df).append(idk_df)\n",
    "balanced_df = balanced_df.reindex(np.random.permutation(balanced_df.index))\n",
    "\n",
    "X = balanced_df\n",
    "y = balanced_df[\"is_clickbait\"]\n",
    "\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8eca88a6d5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m            ]\n\u001b[1;32m     68\u001b[0m })\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 108\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import linear_model\n",
    "\n",
    "class ModelTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        self.model.fit(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(self.model.predict(X))\n",
    "\n",
    "class RoundTransformer(BaseEstimator):\n",
    "    def __init__(self, limit=0.5):\n",
    "        self.limit = limit\n",
    "        \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [ 1.0 if x >= self.limit else 0.0 for x in X[0] ]\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # Ignore the \"i don't know\" click bait titles for scoring later,\n",
    "        # because even if the humans are not sure, it is not a problem for\n",
    "        # the machine to be wrong\n",
    "        y = pd.Series(y).reset_index(drop=True)\n",
    "        indexes = y.index[(y != 0.5)].tolist()\n",
    "        X_test = X.loc[indexes]\n",
    "        y_test = y.loc[indexes]\n",
    "\n",
    "        if len(y_test) == 0:\n",
    "            return 0\n",
    "        \n",
    "        score = accuracy_score(self.predict(X_test), y_test)\n",
    "        return score\n",
    "    \n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=2)),\n",
    "    ('clf', ModelTransformer(RandomForestRegressor())),\n",
    "    ('round', RoundTransformer(limit=0.5))\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipeline, verbose=1, scoring='f1', param_grid={\n",
    "    'round__limit': [0.5, 0.7, 0.3],\n",
    "    'clf': [ModelTransformer(DummyClassifier(\"constant\", constant=1.0)),\n",
    "            ModelTransformer(RandomForestRegressor()),\n",
    "            ModelTransformer(linear_model.LinearRegression()),\n",
    "            ModelTransformer(linear_model.Ridge()),\n",
    "            ModelTransformer(linear_model.ElasticNet()),\n",
    "#             ModelTransformer(linear_model.LassoLars()),\n",
    "#             ModelTransformer(linear_model.OrthogonalMatchingPursuit()),\n",
    "#             ModelTransformer(linear_model.BayesianRidge()),\n",
    "#             ModelTransformer(linear_model.ARDRegression()),\n",
    "#             ModelTransformer(linear_model.LogisticRegression()),\n",
    "#             ModelTransformer(linear_model.SGDRegressor()),\n",
    "            ModelTransformer(linear_model.PassiveAggressiveRegressor()),\n",
    "#             ModelTransformer(linear_model.TheilSenRegressor()),\n",
    "            ModelTransformer(linear_model.HuberRegressor()),\n",
    "#             ModelTransformer(linear_model.RANSACRegressor()),\n",
    "            ModelTransformer(linear_model.Lasso())\n",
    "           ]\n",
    "})\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "results['clf'] = [ p['clf'] for p in results['params'] ]\n",
    "results['round__limit'] = [ p['round__limit'] for p in results['params'] ]\n",
    "results[['clf', 'round__limit', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train on another dataset and score against ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55752212389380529"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cb_titles = clickbait_titles[0].append(buzzfeedbr_clickbait_titles[\"title\"])\n",
    "df2 = pd.DataFrame({\n",
    "        \"title\": all_cb_titles,\n",
    "        \"is_clickbait\": [1] * len(all_cb_titles)\n",
    "    })\n",
    "\n",
    "all_ncb_titles = non_clickbait_titles[0].append(buzzfeedbr_non_clickbait_titles[\"title\"])\n",
    "df2 = df2.append(pd.DataFrame({\n",
    "        \"title\": all_ncb_titles,\n",
    "        \"is_clickbait\": [0] * len(all_ncb_titles)\n",
    "     }), ignore_index=True)\n",
    "df2 = df2.reindex(np.random.permutation(df2.index))\n",
    "\n",
    "X_train = df2[[\"title\"]]\n",
    "y_train = df2[\"is_clickbait\"]\n",
    "\n",
    "df3 = df[(df[\"is_clickbait\"] == 1) | (df[\"is_clickbait\"] == 0)]\n",
    "df3 = df3.reindex(np.random.permutation(df3.index))\n",
    "\n",
    "X_test = df3[[\"title\"]]\n",
    "y_test = df3[\"is_clickbait\"]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=5, token_pattern='[A-Za-z0-9]+')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf = pipeline.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant') \n",
      "[CV]  clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant'), total=   4.3s\n",
      "[CV] clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant') \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant'), total=   3.4s\n",
      "[CV] clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant') \n",
      "[CV]  clf=DummyClassifier(constant=1.0, random_state=None, strategy='constant'), total=   3.2s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), total=   3.1s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), total=   3.0s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), total=   3.0s\n",
      "[CV] clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) \n",
      "[CV]  clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), total=   6.3s\n",
      "[CV] clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) \n",
      "[CV]  clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), total=   6.4s\n",
      "[CV] clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) \n",
      "[CV]  clf=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), total=   6.5s\n",
      "[CV] clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False) \n",
      "[CV]  clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False), total=  54.8s\n",
      "[CV] clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False) \n",
      "[CV]  clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False), total=  53.1s\n",
      "[CV] clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False) \n",
      "[CV]  clf=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False), total=  49.4s\n",
      "[CV] clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False) \n",
      "[CV]  clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), total=   7.7s\n",
      "[CV] clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False) \n",
      "[CV]  clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), total=   7.4s\n",
      "[CV] clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False) \n",
      "[CV]  clf=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), total=   7.5s\n",
      "[CV] clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "[CV]  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), total=   6.3s\n",
      "[CV] clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "[CV]  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), total=   6.0s\n",
      "[CV] clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "[CV]  clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), total=   6.0s\n",
      "[CV] clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False), total=  17.0s\n",
      "[CV] clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) \n",
      "[CV]  clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False), total=  16.9s\n",
      "[CV] clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) \n",
      "[CV]  clf=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False), total=  17.1s\n",
      "[CV] clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) ..\n",
      "[CV]  clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), total=   2.8s\n",
      "[CV] clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) ..\n",
      "[CV]  clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), total=   2.9s\n",
      "[CV] clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) ..\n",
      "[CV]  clf=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), total=   3.4s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), total=   3.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), total=   3.0s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), total=   3.3s\n",
      "[CV] clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False), total= 1.4min\n",
      "[CV] clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False), total= 1.4min\n",
      "[CV] clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=5, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False), total= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 10.0min finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier(constant=1.0, random_state=Non...</td>\n",
       "      <td>0.670003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier(alpha=0.0001, average=False, cla...</td>\n",
       "      <td>0.968237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.884506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.910446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.946726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.933223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.874177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>0.968891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.961380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>0.972639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 clf  mean_test_score\n",
       "0  DummyClassifier(constant=1.0, random_state=Non...         0.670003\n",
       "1  SGDClassifier(alpha=0.0001, average=False, cla...         0.968237\n",
       "2  (DecisionTreeClassifier(class_weight=None, cri...         0.884506\n",
       "3  (DecisionTreeClassifier(class_weight=None, cri...         0.910446\n",
       "4  (ExtraTreeClassifier(class_weight=None, criter...         0.946726\n",
       "5  (DecisionTreeClassifier(class_weight=None, cri...         0.933223\n",
       "6  ([DecisionTreeRegressor(criterion='friedman_ms...         0.874177\n",
       "7  MultinomialNB(alpha=1.0, class_prior=None, fit...         0.968891\n",
       "8  LogisticRegression(C=1.0, class_weight=None, d...         0.961380\n",
       "9  MLPClassifier(activation='relu', alpha=0.0001,...         0.972639"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "df4 = df.append(df2, ignore_index=True)\n",
    "\n",
    "positive_df = df4[df4[\"is_clickbait\"] == 1]\n",
    "negative_df = df4[df4[\"is_clickbait\"] == 0].apply(np.random.permutation)[0:len(positive_df)]\n",
    "balanced_df = positive_df.append(negative_df)\n",
    "balanced_df = balanced_df.reindex(np.random.permutation(balanced_df.index))\n",
    "\n",
    "X = balanced_df\n",
    "y = balanced_df[\"is_clickbait\"]\n",
    "y = [ False if yi == 0 else True for yi in y ]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 3), max_df=0.5, min_df=2, token_pattern='[A-Za-z0-9]+')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipeline, verbose=2, scoring='f1', param_grid={\n",
    "    'clf': [\n",
    "        DummyClassifier(\"constant\", constant=1.0),\n",
    "        SGDClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        MultinomialNB(),\n",
    "        LogisticRegression(),\n",
    "        MLPClassifier(max_iter=5, early_stopping=True),\n",
    "    ],\n",
    "#     'tfidf__max_df': [0.5, 0.1],\n",
    "#     'tfidf__min_df': [2, 5],\n",
    "#     'tfidf__token_pattern': ['[A-Za-z0-9]+', r\"(?u)\\b\\w\\w+\\b\"]\n",
    "})\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "results['clf'] = [ p['clf'] for p in results['params'] ]\n",
    "# results['tfidf__max_df'] = [ p['tfidf__max_df'] for p in results['params'] ]\n",
    "# results['tfidf__min_df'] = [ p['tfidf__min_df'] for p in results['params'] ]\n",
    "# results[['clf', 'tfidf__max_df', 'tfidf__min_df', 'mean_test_score']]\n",
    "results[['clf', 'mean_test_score']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
